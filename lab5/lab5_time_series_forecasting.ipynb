{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting\n",
    "\n",
    "In this notebook you will learn how to perform time series forecasting. In particular, we will develop regression-based forecasting. The content of this notebook is mostly based on the examples of the text book.\n",
    "\n",
    "> (c) 2019 Galit Shmueli, Peter C. Bruce, Peter Gedeck \n",
    ">\n",
    "> Code included in\n",
    ">\n",
    "> _Data Mining for Business Analytics: Concepts, Techniques, and Applications in Python_ (First Edition) \n",
    "> Galit Shmueli, Peter C. Bruce, Peter Gedeck, and Nitin R. Patel. 2019.\n",
    "\n",
    "As always, let's get started by loading all the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:37.707468Z",
     "iopub.status.busy": "2021-05-27T20:03:37.707020Z",
     "iopub.status.idle": "2021-05-27T20:03:38.634422Z",
     "shell.execute_reply": "2021-05-27T20:03:38.633973Z"
    }
   },
   "outputs": [],
   "source": [
    "import dmba\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "from statsmodels.tsa import tsatools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics import tsaplots\n",
    "from plot_utils import graph_layout\n",
    "from plot_utils import single_graph_layout\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The very first step is to load and prepare the data for further analysis. We will use ridership data of the Amtrak railway company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ridership = dmba.load_data('Amtrak.csv')\n",
    "df_ridership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking column types\n",
    "df_ridership.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new column called `Date`, which is basically the Month column transformed to datetime type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ridership['Date'] = pd.to_datetime(df_ridership.Month, format='%d/%m/%Y')\n",
    "df_ridership.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a Pandas series that contains our ridership time series with monthly frequency data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.Series(df_ridership.Ridership.values, index=df_ridership.Date, name='Ridership')\n",
    "df_ts.index = pd.DatetimeIndex(df_ts.index, freq=df_ts.index.inferred_freq)\n",
    "df_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally have a look at our time series using a line plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_ts.plot(figsize=(10,5))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Ridership (in 000s)')\n",
    "ax.set_ylim(1300, 2300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very last preparation step is to add a trend component to the time series for further modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsatools.add_trend(df_ts, trend='ct')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have a constant component, which will help us to fit the intercept, and a trend component, which will be used for the trend. The latter is basically equivalent to each timestep on the series. When we perform a linear fit, we cannot give time directly as a predictor, therefore we create a variable with consecutive numbers, which represents each timestep.\n",
    "\n",
    "\n",
    "## Dataset partition\n",
    "\n",
    "The following step is to divide the data into train and test sets. Remember that for time series we cannot use random sets, as this would create two time series with holes. Therefore we use the earlier periods for training and the later periods for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:38.900892Z",
     "iopub.status.busy": "2021-05-27T20:03:38.900410Z",
     "iopub.status.idle": "2021-05-27T20:03:38.903198Z",
     "shell.execute_reply": "2021-05-27T20:03:38.902832Z"
    }
   },
   "outputs": [],
   "source": [
    "m_test = 36\n",
    "m_train = len(df) - m_test\n",
    "\n",
    "df_train = df[:m_train]\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a dataframe (df_test) with the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling trend\n",
    "\n",
    "As we saw in the theoretical lecture, this time series has a U-shape trend, which indicates that a quadratic function is a good representation for the trend. We will use the `statsmodels` library to fit the trend, the syntax is quite similar to R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_trend = sm.ols(formula='Ridership ~ trend + np.square(trend)', data=df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two predictors (t, t^2). Let's now calculate the residuals, which is the difference between the fit and the actual values, and visualize the results, which also include forecasts for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:39.876890Z",
     "iopub.status.busy": "2021-05-27T20:03:39.875523Z",
     "iopub.status.idle": "2021-05-27T20:03:40.372957Z",
     "shell.execute_reply": "2021-05-27T20:03:40.372538Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9, 7.5))\n",
    "\n",
    "ridership_trend.predict(df_train).plot(ax=axes[0], color='C1')\n",
    "ridership_trend.predict(df_test).plot(ax=axes[0], color='C1', linestyle='dashed')\n",
    "    \n",
    "residual = df_train.Ridership - ridership_trend.predict(df_train)\n",
    "residual.plot(ax=axes[1], color='C1')\n",
    "residual = df_test.Ridership - ridership_trend.predict(df_test)\n",
    "residual.plot(ax=axes[1], color='C1', linestyle='dashed')\n",
    "\n",
    "graph_layout(axes, df_train, df_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a good fit? What do you see in the residuals?\n",
    "\n",
    "-> We can see in the residuals that the trend was well modelled (U-shape removed), but we still see a seasonality pattern left.\n",
    "\n",
    "Let's also have a look at the regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridership_trend.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling seasonality\n",
    "\n",
    "As we discussed in the theoretical lesson, this time series has a monthly seasonal pattern. Let's zoom in to have a better look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_ts['1997':'1999'].plot(figsize=(10,5))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Ridership (in 000s)')\n",
    "ax.set_ylim(1300, 2310)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see that we can easily slice the time series using years, as the dates are used as index?\n",
    "But coming back to the topic of seaslonality, we can model it by creating a categorical variable for the season. So let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsatools.add_trend(df_ts, trend='c')\n",
    "df['Month'] = df.index.month\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-partitioning the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:m_train]\n",
    "df_test = df[m_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the seasonality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_season = sm.ols(formula='Ridership ~ C(Month)', data=df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the residuals and visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:40.418912Z",
     "iopub.status.busy": "2021-05-27T20:03:40.389214Z",
     "iopub.status.idle": "2021-05-27T20:03:40.888834Z",
     "shell.execute_reply": "2021-05-27T20:03:40.888329Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: calculate residuals and visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now? What do you think of this fit?\n",
    "\n",
    "-> The residuals now displays the U-shaped trend.\n",
    "\n",
    "It is also useful to check the regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:40.894120Z",
     "iopub.status.busy": "2021-05-27T20:03:40.892990Z",
     "iopub.status.idle": "2021-05-27T20:03:40.905791Z",
     "shell.execute_reply": "2021-05-27T20:03:40.905323Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: print the regression results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling trend and seasonality\n",
    "\n",
    "We can see that we need to add both the trend and seasonality to get a proper model. So let's do it, but before we will do some quick data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "df = tsatools.add_trend(df_ts, trend='ct')\n",
    "df['Month'] = df.index.month\n",
    "\n",
    "# Partition the data\n",
    "df_train = df[:m_train]\n",
    "df_test = df[m_train:]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a model with both trend and seasonality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create and fit a model with both trend and seasonality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:40.916498Z",
     "iopub.status.busy": "2021-05-27T20:03:40.916051Z",
     "iopub.status.idle": "2021-05-27T20:03:41.503300Z",
     "shell.execute_reply": "2021-05-27T20:03:41.502909Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: calculate the residuals and plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can print the regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of this model? Can it still be improved?\n",
    "\n",
    "-> The current model is much better, but it can still be improved!\n",
    "\n",
    "\n",
    "## Autocorrelation\n",
    "\n",
    "We saw in the theoretical lecture that autocorrelation is basically a measure of the correlation of a series and itself, more precisely its lagged versions. Let's have a look at the autocorrelation plot for this time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:41.527377Z",
     "iopub.status.busy": "2021-05-27T20:03:41.526933Z",
     "iopub.status.idle": "2021-05-27T20:03:41.695294Z",
     "shell.execute_reply": "2021-05-27T20:03:41.694825Z"
    }
   },
   "outputs": [],
   "source": [
    "tsaplots.plot_acf(df_train['1991-01-01':'1993-01-01'].Ridership)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a strong correlation at lag-6, which is statistically significant as it falls outside of the blue region. The high correlation at lag-6 is basically due to the high summers and low winters pattern. Let's now check the autocorrelation of the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assign your previous model (with trend and seasonality) to the ridership_trend_season variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:41.731670Z",
     "iopub.status.busy": "2021-05-27T20:03:41.726970Z",
     "iopub.status.idle": "2021-05-27T20:03:41.879301Z",
     "shell.execute_reply": "2021-05-27T20:03:41.878871Z"
    }
   },
   "outputs": [],
   "source": [
    "residual = df_train.Ridership - ridership_trend_season.predict(df_train)\n",
    "tsaplots.plot_acf(residual)\n",
    "plt.xlim(-1, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see positive correlation for all the lags, with lags 1 to 3 outside the 95% confidence interval, which indicates that the model can still be improved. That was also visible in the residuals. We can improve this model using a second-level forecast. A way of doing that is to use our original model and add a correction term. This correction term can be estimated by running an autoregressive model on the residuals. So let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_arima = ARIMA(ridership_trend_season.resid, order=(1, 0, 0), freq='MS').fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained an autoregressive model of order 1 on the residuals of the original model. Let's have a look at the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:41.894574Z",
     "iopub.status.busy": "2021-05-27T20:03:41.893734Z",
     "iopub.status.idle": "2021-05-27T20:03:41.924533Z",
     "shell.execute_reply": "2021-05-27T20:03:41.924170Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'coef': train_res_arima.params, 'std err': train_res_arima.bse}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize as a line plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:41.992314Z",
     "iopub.status.busy": "2021-05-27T20:03:41.967670Z",
     "iopub.status.idle": "2021-05-27T20:03:42.204036Z",
     "shell.execute_reply": "2021-05-27T20:03:42.203657Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = ridership_trend_season.resid.plot(figsize=(9,4))\n",
    "train_res_arima.fittedvalues.plot(ax=ax)\n",
    "single_graph_layout(ax, [-250, 250], df_train, df_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecast for the error on April 2001 can be obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_arima.forecast(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the forecast for ridership on April 2001 can be obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_trend_season.predict(df_test).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our second-level forecast for April 2001 would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_trend_season.predict(df_test).values[0] + train_res_arima.forecast(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the observed ridership is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['2001-04-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the second-level forecast provides a better estimation. Let's have a look at the autocorrelation plot for the residuals-of-residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T20:03:42.231521Z",
     "iopub.status.busy": "2021-05-27T20:03:42.229609Z",
     "iopub.status.idle": "2021-05-27T20:03:42.377391Z",
     "shell.execute_reply": "2021-05-27T20:03:42.377020Z"
    }
   },
   "outputs": [],
   "source": [
    "tsaplots.plot_acf(train_res_arima.resid)\n",
    "plt.xlim(-1, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that autocorrelation was removed, which indicates a good model. Now you know how to build a regression-based forecast and how to use autoregressive models to improve forecasts. Notice, however, that using autoregressive models on the residuals can provide a good estimation for the error only for short-term forecasts. The problem here is that we need to know the error of past values to forecast the error of future values. If we look too far into the future, we would need to use forecasts for these errors, which would add too much uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
